{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation as punct\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk import word_tokenize\n",
    "import torch \n",
    "\n",
    "stops = stopwords.words('russian')\n",
    "punct+=' –'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t.zhordaniya/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f3bf8660ad40aa9530735754660362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t.zhordaniya/venv/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm.auto import tqdm\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='182/model.bin.gz'\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'A': 'ADJ', 'ADV': 'ADV', 'ADVPRO': 'ADV', 'ANUM': 'ADJ', 'APRO': 'DET', 'COM': 'ADJ', 'CONJ': 'SCONJ', 'INTJ': 'INTJ', 'NONLEX': 'X', 'NUM': 'NUM', 'PART': 'PART', 'PR': 'ADP', 'S': 'NOUN', 'SPRO': 'PRON', 'UNKN': 'X', 'V': 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "def tag_mystem(text):  \n",
    "    \n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "            if pos in mapping:\n",
    "                tagged.append(lemma + '_' + mapping[pos]) \n",
    "            else:\n",
    "                tagged.append(lemma + '_X') \n",
    "        except:\n",
    "            continue \n",
    "    return ' '.join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/main/active-dict/train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033c6bca8f8146d794edc94f21541af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2073.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['context_tagged'] = df_train['context'].progress_apply(tag_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tagret(x):\n",
    "    try: \n",
    "        return [word for word in x.context_lem.split() if word.split('_')[0]==x.word][0]\n",
    "    except:\n",
    "        return tag_mystem(x.word)\n",
    "    \n",
    "def del_stops(context):\n",
    "    \n",
    "    w = [word for word in context.split() if word.split('_')[0] not in stops]\n",
    "    return ' '.join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306fe124dd7e43eca01883cb8c8f932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2073.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['target'] = df_train.progress_apply(find_tagret, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ebd3f87d6d416dbe6e193015fa30c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2073.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['context_cleaned'] = df_train['context_tagged'].progress_apply(del_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tagged</th>\n",
       "      <th>target</th>\n",
       "      <th>context_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-22</td>\n",
       "      <td>Отвергнуть щедрый дар</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21-28</td>\n",
       "      <td>покупать преданность дарами и наградами</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN и_SCON...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN наград...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19-23</td>\n",
       "      <td>Вот яд – последний дар моей Изоры</td>\n",
       "      <td>вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>яд_NOUN последний_ADJ дар_NOUN изор_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81-87</td>\n",
       "      <td>Основная функция корильных песен – повеселить ...</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151-157</td>\n",
       "      <td>Но недели две спустя (Алевтина его когда-то об...</td>\n",
       "      <td>но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2069</td>\n",
       "      <td>зонт</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85-91</td>\n",
       "      <td>Такая погода легко переживается весной, а вот ...</td>\n",
       "      <td>такой_DET погода_NOUN легко_ADV переживаться_V...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>погода_NOUN легко_ADV переживаться_VERB весна_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>2070</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8-13</td>\n",
       "      <td>Пляжный зонт</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2071</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-25</td>\n",
       "      <td>сидеть в кафе под зонтом</td>\n",
       "      <td>сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>сидеть_VERB кафе_NOUN зонт_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2072</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21-29</td>\n",
       "      <td>Cтолики под широкими зонтами, несколько привин...</td>\n",
       "      <td>столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2073</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62-70</td>\n",
       "      <td>Я выскочила из Исторического музея в летнее ка...</td>\n",
       "      <td>я_PRON выскочить_VERB из_ADP исторический_ADJ ...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>выскочить_VERB исторический_ADJ музей_NOUN лет...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id  word gold_sense_id  predict_sense_id positions  \\\n",
       "0              1   дар             1               NaN     18-22   \n",
       "1              2   дар             1               NaN     21-28   \n",
       "2              3   дар             1               NaN     19-23   \n",
       "3              4   дар             1               NaN     81-87   \n",
       "4              5   дар             1               NaN   151-157   \n",
       "...          ...   ...           ...               ...       ...   \n",
       "2068        2069  зонт             1               NaN     85-91   \n",
       "2069        2070  зонт             2               NaN      8-13   \n",
       "2070        2071  зонт             2               NaN     18-25   \n",
       "2071        2072  зонт             2               NaN     21-29   \n",
       "2072        2073  зонт             2               NaN     62-70   \n",
       "\n",
       "                                                context  \\\n",
       "0                                 Отвергнуть щедрый дар   \n",
       "1               покупать преданность дарами и наградами   \n",
       "2                     Вот яд – последний дар моей Изоры   \n",
       "3     Основная функция корильных песен – повеселить ...   \n",
       "4     Но недели две спустя (Алевтина его когда-то об...   \n",
       "...                                                 ...   \n",
       "2068  Такая погода легко переживается весной, а вот ...   \n",
       "2069                                       Пляжный зонт   \n",
       "2070                           сидеть в кафе под зонтом   \n",
       "2071  Cтолики под широкими зонтами, несколько привин...   \n",
       "2072  Я выскочила из Исторического музея в летнее ка...   \n",
       "\n",
       "                                         context_tagged     target  \\\n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN   дар_NOUN   \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN и_SCON...   дар_NOUN   \n",
       "2     вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...   дар_NOUN   \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...   дар_NOUN   \n",
       "4     но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...   дар_NOUN   \n",
       "...                                                 ...        ...   \n",
       "2068  такой_DET погода_NOUN легко_ADV переживаться_V...  зонт_NOUN   \n",
       "2069                              пляжный_ADJ зонт_NOUN  зонт_NOUN   \n",
       "2070      сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN  зонт_NOUN   \n",
       "2071  столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...  зонт_NOUN   \n",
       "2072  я_PRON выскочить_VERB из_ADP исторический_ADJ ...  зонт_NOUN   \n",
       "\n",
       "                                        context_cleaned  \n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN  \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN наград...  \n",
       "2              яд_NOUN последний_ADJ дар_NOUN изор_NOUN  \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...  \n",
       "4     неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...  \n",
       "...                                                 ...  \n",
       "2068  погода_NOUN легко_ADV переживаться_VERB весна_...  \n",
       "2069                              пляжный_ADJ зонт_NOUN  \n",
       "2070                    сидеть_VERB кафе_NOUN зонт_NOUN  \n",
       "2071  столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...  \n",
       "2072  выскочить_VERB исторический_ADJ музей_NOUN лет...  \n",
       "\n",
       "[2073 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vectors(x):\n",
    "    vectors=[]\n",
    "    context = x.context_cleaned\n",
    "    words = list(set([word for word in context.split() if word != x.target and word in word2vec]))\n",
    "    if not words:\n",
    "        words = [x.target]\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        \n",
    "        vectors.append(word2vec[word])\n",
    "\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_wor2vec(df):\n",
    "    predicted = []\n",
    "\n",
    "    for word in df['word'].unique():\n",
    "\n",
    "        word_df = df[df['word'] == word]\n",
    "\n",
    "\n",
    "        vectors = word_df.apply(average_vectors, axis=1) \n",
    "\n",
    "        matrix=np.vstack(vectors)\n",
    "\n",
    "        clustering = AffinityPropagation(preference=-0.7, damping=0.7).fit(matrix)\n",
    "        nclusters = len(clustering.cluster_centers_indices_)\n",
    "\n",
    "        if nclusters < 1:\n",
    "            nclusters = 1\n",
    "        elif nclusters == len(word_df):\n",
    "            nclusters = 4\n",
    "\n",
    "        clustering = SpectralClustering(n_clusters=nclusters, n_init=20,\n",
    "                                        assign_labels='discretize', n_jobs=2).fit(matrix)\n",
    "\n",
    "        cur_predicted = clustering.labels_.tolist()\n",
    "        predicted += cur_predicted\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['predict_sense_id'] = predict_wor2vec(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\tari\tcount\r\n",
      "дар\t0.108842\t36\r\n",
      "двигатель\t0.188742\t15\r\n",
      "двойник\t0.096693\t25\r\n",
      "дворец\t0.190661\t13\r\n",
      "девятка\t0.135668\t47\r\n",
      "дедушка\t0.100000\t9\r\n",
      "дежурная\t0.050139\t12\r\n",
      "дежурный\t0.122699\t13\r\n",
      "декабрист\t0.485981\t11\r\n",
      "декрет\t0.554913\t12\r\n",
      "дело\t0.011877\t130\r\n",
      "демобилизация\t0.548163\t14\r\n",
      "демократ\t-0.030222\t18\r\n",
      "демонстрация\t0.099838\t38\r\n",
      "дерево\t0.552239\t21\r\n",
      "держава\t0.171053\t15\r\n",
      "дерзость\t0.087616\t37\r\n",
      "десятка\t0.102005\t36\r\n",
      "десяток\t0.080195\t21\r\n",
      "деятель\t0.494700\t14\r\n",
      "диалог\t0.313380\t14\r\n",
      "диаметр\t0.194030\t18\r\n",
      "диплом\t0.226384\t25\r\n",
      "директор\t0.044118\t11\r\n",
      "диск\t0.168480\t63\r\n",
      "дичь\t0.491887\t18\r\n",
      "длина\t-0.074024\t21\r\n",
      "доброволец\t0.250710\t12\r\n",
      "добыча\t0.212836\t35\r\n",
      "доказательство\t0.139383\t24\r\n",
      "доктор\t0.276596\t17\r\n",
      "долгота\t0.011696\t13\r\n",
      "доля\t0.089024\t45\r\n",
      "дом\t0.137362\t38\r\n",
      "дорога\t0.019604\t47\r\n",
      "достижение\t0.068511\t22\r\n",
      "древесина\t0.076133\t16\r\n",
      "дупло\t0.731065\t15\r\n",
      "дура\t0.693593\t12\r\n",
      "дух\t0.102564\t77\r\n",
      "дым\t0.499006\t28\r\n",
      "дымка\t0.520376\t18\r\n",
      "дыхание\t0.123509\t56\r\n",
      "дьявол\t0.205078\t22\r\n",
      "евро\t0.166667\t8\r\n",
      "езда\t-0.053038\t14\r\n",
      "жаворонок\t0.236111\t11\r\n",
      "жало\t0.000000\t11\r\n",
      "жертва\t0.005011\t37\r\n",
      "жестокость\t0.001950\t14\r\n",
      "жидкость\t-0.096866\t12\r\n",
      "жила\t0.516333\t17\r\n",
      "жилец\t0.080851\t16\r\n",
      "жир\t0.328947\t15\r\n",
      "жребий\t0.451697\t15\r\n",
      "заведение\t0.589474\t14\r\n",
      "завещание\t0.333333\t16\r\n",
      "зависимость\t0.166585\t21\r\n",
      "заголовок\t0.148327\t22\r\n",
      "заготовка\t0.371498\t26\r\n",
      "задание\t0.148842\t33\r\n",
      "задача\t0.009016\t36\r\n",
      "задержка\t0.006164\t60\r\n",
      "зажигалка\t0.355372\t13\r\n",
      "закон\t0.139202\t56\r\n",
      "закрытие\t0.325128\t38\r\n",
      "заложник\t-0.022472\t13\r\n",
      "замена\t0.084627\t18\r\n",
      "западня\t0.340879\t11\r\n",
      "запятая\t0.103771\t14\r\n",
      "застой\t0.736842\t13\r\n",
      "затея\t-0.037221\t12\r\n",
      "затишье\t0.206299\t16\r\n",
      "затмение\t0.498575\t12\r\n",
      "затруднение\t0.168049\t15\r\n",
      "захоронение\t0.195122\t22\r\n",
      "звезда\t0.273849\t40\r\n",
      "звон\t0.037500\t14\r\n",
      "зеркало\t0.400000\t21\r\n",
      "зло\t0.161709\t23\r\n",
      "злоупотребление\t0.562914\t12\r\n",
      "знак\t0.115940\t55\r\n",
      "знамя\t-0.007703\t14\r\n",
      "значение\t0.320788\t30\r\n",
      "зонт\t0.225166\t9\r\n",
      "\t0.176091\t2073\r\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate.py df_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим алгоритм на корпусе "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/additional/active-rutenten/train.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca486bf7e904bccb32a8baf4f0e1b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f79f347b2c41f0ae7e14e3e0333d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f21a67b4d3946ca8766236163ace003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test['context_tagged'] = df_test['context'].progress_apply(tag_mystem)\n",
    "df_test['target'] = df_test.progress_apply(find_tagret, axis=1)\n",
    "df_test['context_cleaned'] = df_test['context_tagged'].progress_apply(del_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predict_sense_id'] = predict_wor2vec(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('df_test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\tari\tcount\r\n",
      "альбом\t0.048016\t450\r\n",
      "анатомия\t0.007360\t95\r\n",
      "базар\t0.048682\t90\r\n",
      "балет\t0.114912\t94\r\n",
      "беда\t0.047208\t93\r\n",
      "бездна\t0.013397\t87\r\n",
      "билет\t-0.010174\t447\r\n",
      "блок\t0.272103\t206\r\n",
      "блоха\t-0.004986\t86\r\n",
      "брак\t0.033178\t96\r\n",
      "бритва\t0.004670\t85\r\n",
      "будущее\t-0.005635\t83\r\n",
      "вешалка\t0.059043\t390\r\n",
      "вилка\t0.374105\t302\r\n",
      "винт\t0.230417\t358\r\n",
      "галерея\t0.169550\t24\r\n",
      "горбуша\t0.520626\t93\r\n",
      "горшок\t0.167009\t406\r\n",
      "гроза\t-0.041698\t95\r\n",
      "группа\t0.128040\t91\r\n",
      "\t0.120870\t3671\r\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate.py df_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tagged</th>\n",
       "      <th>target</th>\n",
       "      <th>context_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18-22</td>\n",
       "      <td>Отвергнуть щедрый дар</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21-28</td>\n",
       "      <td>покупать преданность дарами и наградами</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN и_SCON...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN наград...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-23</td>\n",
       "      <td>Вот яд – последний дар моей Изоры</td>\n",
       "      <td>вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>яд_NOUN последний_ADJ дар_NOUN изор_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81-87</td>\n",
       "      <td>Основная функция корильных песен – повеселить ...</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151-157</td>\n",
       "      <td>Но недели две спустя (Алевтина его когда-то об...</td>\n",
       "      <td>но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2069</td>\n",
       "      <td>зонт</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85-91</td>\n",
       "      <td>Такая погода легко переживается весной, а вот ...</td>\n",
       "      <td>такой_DET погода_NOUN легко_ADV переживаться_V...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>погода_NOUN легко_ADV переживаться_VERB весна_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>2070</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8-13</td>\n",
       "      <td>Пляжный зонт</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2071</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18-25</td>\n",
       "      <td>сидеть в кафе под зонтом</td>\n",
       "      <td>сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>сидеть_VERB кафе_NOUN зонт_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2072</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21-29</td>\n",
       "      <td>Cтолики под широкими зонтами, несколько привин...</td>\n",
       "      <td>столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2073</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>62-70</td>\n",
       "      <td>Я выскочила из Исторического музея в летнее ка...</td>\n",
       "      <td>я_PRON выскочить_VERB из_ADP исторический_ADJ ...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>выскочить_VERB исторический_ADJ музей_NOUN лет...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id  word gold_sense_id  predict_sense_id positions  \\\n",
       "0              1   дар             1                 3     18-22   \n",
       "1              2   дар             1                 0     21-28   \n",
       "2              3   дар             1                 0     19-23   \n",
       "3              4   дар             1                 0     81-87   \n",
       "4              5   дар             1                 0   151-157   \n",
       "...          ...   ...           ...               ...       ...   \n",
       "2068        2069  зонт             1                 2     85-91   \n",
       "2069        2070  зонт             2                 0      8-13   \n",
       "2070        2071  зонт             2                 3     18-25   \n",
       "2071        2072  зонт             2                 1     21-29   \n",
       "2072        2073  зонт             2                 3     62-70   \n",
       "\n",
       "                                                context  \\\n",
       "0                                 Отвергнуть щедрый дар   \n",
       "1               покупать преданность дарами и наградами   \n",
       "2                     Вот яд – последний дар моей Изоры   \n",
       "3     Основная функция корильных песен – повеселить ...   \n",
       "4     Но недели две спустя (Алевтина его когда-то об...   \n",
       "...                                                 ...   \n",
       "2068  Такая погода легко переживается весной, а вот ...   \n",
       "2069                                       Пляжный зонт   \n",
       "2070                           сидеть в кафе под зонтом   \n",
       "2071  Cтолики под широкими зонтами, несколько привин...   \n",
       "2072  Я выскочила из Исторического музея в летнее ка...   \n",
       "\n",
       "                                         context_tagged     target  \\\n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN   дар_NOUN   \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN и_SCON...   дар_NOUN   \n",
       "2     вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...   дар_NOUN   \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...   дар_NOUN   \n",
       "4     но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...   дар_NOUN   \n",
       "...                                                 ...        ...   \n",
       "2068  такой_DET погода_NOUN легко_ADV переживаться_V...  зонт_NOUN   \n",
       "2069                              пляжный_ADJ зонт_NOUN  зонт_NOUN   \n",
       "2070      сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN  зонт_NOUN   \n",
       "2071  столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...  зонт_NOUN   \n",
       "2072  я_PRON выскочить_VERB из_ADP исторический_ADJ ...  зонт_NOUN   \n",
       "\n",
       "                                        context_cleaned  \n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN  \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN наград...  \n",
       "2              яд_NOUN последний_ADJ дар_NOUN изор_NOUN  \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...  \n",
       "4     неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...  \n",
       "...                                                 ...  \n",
       "2068  погода_NOUN легко_ADV переживаться_VERB весна_...  \n",
       "2069                              пляжный_ADJ зонт_NOUN  \n",
       "2070                    сидеть_VERB кафе_NOUN зонт_NOUN  \n",
       "2071  столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...  \n",
       "2072  выскочить_VERB исторический_ADJ музей_NOUN лет...  \n",
       "\n",
       "[2073 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А что с бертом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интуиция:\n",
    "\n",
    "\n",
    "\n",
    "1) получить контекстно-зависимый эмбеддинг всего предложения\n",
    "\n",
    "2) по индексу найти нужное нам слово\n",
    "\n",
    "3) усреднить эмбеддинги словев этого слова (последние 4 слоя)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['positions'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train['positions'].isnull()]) # несколько битых строк, можно от них избавиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['positions'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто токенизируем предложения и приведем к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word not in stops and word not in punct]\n",
    "    res = []\n",
    "    for token in tokens:\n",
    "        if token:\n",
    "            res.extend(token.split('-'))\n",
    "        \n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokenized'] = df_train['context'].apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_positions(x):\n",
    "    target_words = []\n",
    "    pos = [i.split('-') for i in x.positions.split(',')]\n",
    "    \n",
    "    for position in pos:\n",
    "        target_words.append(x.context[int(position[0]):int(position[1])-1])\n",
    "    \n",
    "    return target_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target2'] = df_train.progress_apply(parse_positions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets= df_train['target2'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tagged</th>\n",
       "      <th>target</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18-22</td>\n",
       "      <td>Отвергнуть щедрый дар</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>отвергать_VERB щедрый_ADJ дар_NOUN</td>\n",
       "      <td>отвергнуть щедрый дар</td>\n",
       "      <td>дар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21-28</td>\n",
       "      <td>покупать преданность дарами и наградами</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN и_SCON...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>покупать_VERB преданность_NOUN дар_NOUN наград...</td>\n",
       "      <td>покупать преданность дарами наградами</td>\n",
       "      <td>дарами</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-23</td>\n",
       "      <td>Вот яд – последний дар моей Изоры</td>\n",
       "      <td>вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>яд_NOUN последний_ADJ дар_NOUN изор_NOUN</td>\n",
       "      <td>вот яд последний дар моей изоры</td>\n",
       "      <td>дар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81-87</td>\n",
       "      <td>Основная функция корильных песен – повеселить ...</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>основной_ADJ функция_NOUN корильный_ADJ песня_...</td>\n",
       "      <td>основная функция корильных песен повеселить уч...</td>\n",
       "      <td>дарам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151-157</td>\n",
       "      <td>Но недели две спустя (Алевтина его когда-то об...</td>\n",
       "      <td>но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...</td>\n",
       "      <td>дар_NOUN</td>\n",
       "      <td>неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...</td>\n",
       "      <td>но недели две спустя алевтина когда то просила...</td>\n",
       "      <td>даров</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>2069</td>\n",
       "      <td>зонт</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85-91</td>\n",
       "      <td>Такая погода легко переживается весной, а вот ...</td>\n",
       "      <td>такой_DET погода_NOUN легко_ADV переживаться_V...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>погода_NOUN легко_ADV переживаться_VERB весна_...</td>\n",
       "      <td>такая погода легко переживается весной осенью ...</td>\n",
       "      <td>зонта</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>2070</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8-13</td>\n",
       "      <td>Пляжный зонт</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>пляжный_ADJ зонт_NOUN</td>\n",
       "      <td>пляжный зонт</td>\n",
       "      <td>зонт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2071</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18-25</td>\n",
       "      <td>сидеть в кафе под зонтом</td>\n",
       "      <td>сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>сидеть_VERB кафе_NOUN зонт_NOUN</td>\n",
       "      <td>сидеть кафе зонтом</td>\n",
       "      <td>зонтом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2072</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21-29</td>\n",
       "      <td>Cтолики под широкими зонтами, несколько привин...</td>\n",
       "      <td>столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...</td>\n",
       "      <td>cтолики широкими зонтами несколько привинченны...</td>\n",
       "      <td>зонтами</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2073</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>62-70</td>\n",
       "      <td>Я выскочила из Исторического музея в летнее ка...</td>\n",
       "      <td>я_PRON выскочить_VERB из_ADP исторический_ADJ ...</td>\n",
       "      <td>зонт_NOUN</td>\n",
       "      <td>выскочить_VERB исторический_ADJ музей_NOUN лет...</td>\n",
       "      <td>я выскочила исторического музея летнее кафе бо...</td>\n",
       "      <td>зонтами</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2040 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id  word gold_sense_id  predict_sense_id positions  \\\n",
       "0              1   дар             1                 3     18-22   \n",
       "1              2   дар             1                 0     21-28   \n",
       "2              3   дар             1                 0     19-23   \n",
       "3              4   дар             1                 0     81-87   \n",
       "4              5   дар             1                 0   151-157   \n",
       "...          ...   ...           ...               ...       ...   \n",
       "2068        2069  зонт             1                 2     85-91   \n",
       "2069        2070  зонт             2                 0      8-13   \n",
       "2070        2071  зонт             2                 3     18-25   \n",
       "2071        2072  зонт             2                 1     21-29   \n",
       "2072        2073  зонт             2                 3     62-70   \n",
       "\n",
       "                                                context  \\\n",
       "0                                 Отвергнуть щедрый дар   \n",
       "1               покупать преданность дарами и наградами   \n",
       "2                     Вот яд – последний дар моей Изоры   \n",
       "3     Основная функция корильных песен – повеселить ...   \n",
       "4     Но недели две спустя (Алевтина его когда-то об...   \n",
       "...                                                 ...   \n",
       "2068  Такая погода легко переживается весной, а вот ...   \n",
       "2069                                       Пляжный зонт   \n",
       "2070                           сидеть в кафе под зонтом   \n",
       "2071  Cтолики под широкими зонтами, несколько привин...   \n",
       "2072  Я выскочила из Исторического музея в летнее ка...   \n",
       "\n",
       "                                         context_tagged     target  \\\n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN   дар_NOUN   \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN и_SCON...   дар_NOUN   \n",
       "2     вот_PART яд_NOUN последний_ADJ дар_NOUN мой_DE...   дар_NOUN   \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...   дар_NOUN   \n",
       "4     но_SCONJ неделя_NOUN два_NUM спустя_ADP алевти...   дар_NOUN   \n",
       "...                                                 ...        ...   \n",
       "2068  такой_DET погода_NOUN легко_ADV переживаться_V...  зонт_NOUN   \n",
       "2069                              пляжный_ADJ зонт_NOUN  зонт_NOUN   \n",
       "2070      сидеть_VERB в_ADP кафе_NOUN под_ADP зонт_NOUN  зонт_NOUN   \n",
       "2071  столик_NOUN под_ADP широкий_ADJ зонт_NOUN неск...  зонт_NOUN   \n",
       "2072  я_PRON выскочить_VERB из_ADP исторический_ADJ ...  зонт_NOUN   \n",
       "\n",
       "                                        context_cleaned  \\\n",
       "0                    отвергать_VERB щедрый_ADJ дар_NOUN   \n",
       "1     покупать_VERB преданность_NOUN дар_NOUN наград...   \n",
       "2              яд_NOUN последний_ADJ дар_NOUN изор_NOUN   \n",
       "3     основной_ADJ функция_NOUN корильный_ADJ песня_...   \n",
       "4     неделя_NOUN спустя_ADP алевтина_NOUN когда-то_...   \n",
       "...                                                 ...   \n",
       "2068  погода_NOUN легко_ADV переживаться_VERB весна_...   \n",
       "2069                              пляжный_ADJ зонт_NOUN   \n",
       "2070                    сидеть_VERB кафе_NOUN зонт_NOUN   \n",
       "2071  столик_NOUN широкий_ADJ зонт_NOUN несколько_NU...   \n",
       "2072  выскочить_VERB исторический_ADJ музей_NOUN лет...   \n",
       "\n",
       "                                              tokenized  target2  \n",
       "0                                 отвергнуть щедрый дар      дар  \n",
       "1                 покупать преданность дарами наградами   дарами  \n",
       "2                       вот яд последний дар моей изоры      дар  \n",
       "3     основная функция корильных песен повеселить уч...    дарам  \n",
       "4     но недели две спустя алевтина когда то просила...    даров  \n",
       "...                                                 ...      ...  \n",
       "2068  такая погода легко переживается весной осенью ...    зонта  \n",
       "2069                                       пляжный зонт     зонт  \n",
       "2070                                 сидеть кафе зонтом   зонтом  \n",
       "2071  cтолики широкими зонтами несколько привинченны...  зонтами  \n",
       "2072  я выскочила исторического музея летнее кафе бо...  зонтами  \n",
       "\n",
       "[2040 rows x 11 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', never_split=targets)\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(x):\n",
    "\n",
    "    \n",
    "    tagret_id = tokenizer.encode(x.target2, add_special_tokens=False)[0]\n",
    "    \n",
    "    tokens = tokenizer.encode(x.tokenized, add_special_tokens=False)\n",
    "    \n",
    "    if tagret_id in tokens:\n",
    "        \n",
    "        target_position = tokens.index(tagret_id)\n",
    "        data.append((tokens, x.target2, target_position))\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise Exception('Пустой массив!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_4(matrix, hdim=768, nlayers=13):\n",
    "\n",
    "    split = np.split(matrix[:, hdim:], nlayers - 1, axis=1)\n",
    "\n",
    "    return np.mean(np.array(split[-4:]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'damping': 0.7,\n",
    "        'max_iter': 150,\n",
    "        'convergence_iter': 150,\n",
    "        'preference': None,\n",
    "        'affinity': 'euclidean'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eedbc9d66a412ead3eb8c1728bd5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "\n",
    "spectral = False\n",
    "\n",
    "\n",
    "for word in tqdm(df_train['word'].unique().tolist()):\n",
    "    \n",
    "    n = df_train[df_train['word']==word]\n",
    "    \n",
    "\n",
    "    data=[]\n",
    "    \n",
    "    n.apply(get_vector, axis=1) # заполняет data\n",
    "    \n",
    "    \n",
    "    vectors=[]\n",
    "\n",
    "    for _tuple in data:\n",
    "    \n",
    "\n",
    "        input_ids = _tuple[0]\n",
    "        \n",
    "        lemmas, pos = _tuple[1], _tuple[2]\n",
    "        \n",
    "        outputs = model(torch.tensor(input_ids).unsqueeze(0))\n",
    "        \n",
    "        hidden_states = [l.detach().cpu().clone().numpy() for l in outputs[2]]\n",
    "\n",
    "        layers= [layer[:,pos,:] for layer in hidden_states]\n",
    "        \n",
    "        \n",
    "        vector = np.concatenate(layers, axis=1)\n",
    "\n",
    "        vectors.append(mean_4(vector))\n",
    "        \n",
    "    \n",
    "    \n",
    "    matrix=np.vstack(vectors)\n",
    "        \n",
    "    \n",
    "    clustering = AffinityPropagation(**params).fit(matrix)\n",
    "        \n",
    "    \n",
    "    if spectral:\n",
    "        \n",
    "        nclusters = len(clustering.cluster_centers_indices_)\n",
    "        \n",
    "        if nclusters < 1:\n",
    "            nclusters = 1\n",
    "        elif nclusters == len(n):\n",
    "            nclusters = 4\n",
    "            \n",
    "        clustering = SpectralClustering(n_clusters=4, n_init=20,\n",
    "                                        assign_labels='discretize', n_jobs=2).fit(matrix)     \n",
    "    \n",
    "    \n",
    "    cur_pred = clustering.labels_.tolist()\n",
    "    \n",
    "    predicted += cur_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t.zhordaniya/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['predict_sense_id'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('bert.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\tari\tcount\r\n",
      "дар\t0.032451\t36\r\n",
      "двигатель\t0.284169\t14\r\n",
      "двойник\t0.002397\t25\r\n",
      "дворец\t0.065708\t13\r\n",
      "девятка\t0.022225\t47\r\n",
      "дедушка\t-0.117647\t9\r\n",
      "дежурная\t-0.103152\t12\r\n",
      "дежурный\t0.075099\t13\r\n",
      "декабрист\t0.154977\t11\r\n",
      "декрет\t0.216524\t12\r\n",
      "дело\t0.077767\t129\r\n",
      "демобилизация\t0.006791\t14\r\n",
      "демократ\t-0.036585\t18\r\n",
      "демонстрация\t0.046488\t37\r\n",
      "дерево\t0.094118\t21\r\n",
      "держава\t-0.041940\t15\r\n",
      "дерзость\t0.040280\t37\r\n",
      "десятка\t0.020149\t36\r\n",
      "десяток\t0.057729\t20\r\n",
      "деятель\t-0.045455\t14\r\n",
      "диалог\t-0.066318\t14\r\n",
      "диаметр\t-0.108209\t18\r\n",
      "диплом\t-0.023192\t25\r\n",
      "директор\t-0.054197\t11\r\n",
      "диск\t0.040095\t62\r\n",
      "дичь\t-0.092369\t18\r\n",
      "длина\t-0.040971\t21\r\n",
      "доброволец\t0.145733\t12\r\n",
      "добыча\t0.072234\t35\r\n",
      "доказательство\t-0.030292\t24\r\n",
      "доктор\t0.164433\t17\r\n",
      "долгота\t-0.081136\t13\r\n",
      "доля\t0.132302\t45\r\n",
      "дом\t0.140916\t36\r\n",
      "дорога\t0.070022\t47\r\n",
      "достижение\t-0.004785\t22\r\n",
      "древесина\t-0.074727\t16\r\n",
      "дупло\t0.036344\t15\r\n",
      "дура\t0.015843\t12\r\n",
      "дух\t-0.031653\t75\r\n",
      "дым\t0.001312\t28\r\n",
      "дымка\t0.045850\t18\r\n",
      "дыхание\t0.074559\t55\r\n",
      "дьявол\t-0.005613\t22\r\n",
      "евро\t0.000000\t8\r\n",
      "езда\t0.083013\t14\r\n",
      "жаворонок\t0.054054\t10\r\n",
      "жало\t0.115756\t11\r\n",
      "жертва\t-0.035978\t37\r\n",
      "жестокость\t-0.073746\t14\r\n",
      "жидкость\t-0.043360\t12\r\n",
      "жила\t-0.177570\t7\r\n",
      "жилец\t-0.051739\t16\r\n",
      "жир\t-0.010568\t15\r\n",
      "жребий\t-0.068702\t15\r\n",
      "заведение\t0.475422\t11\r\n",
      "завещание\t0.033333\t16\r\n",
      "зависимость\t-0.033058\t21\r\n",
      "заголовок\t0.088630\t22\r\n",
      "заготовка\t-0.025939\t26\r\n",
      "задание\t0.056454\t33\r\n",
      "задача\t0.106686\t36\r\n",
      "задержка\t0.089445\t55\r\n",
      "зажигалка\t-0.083333\t13\r\n",
      "закон\t0.056938\t56\r\n",
      "закрытие\t0.035850\t37\r\n",
      "заложник\t-0.024896\t13\r\n",
      "замена\t0.203390\t16\r\n",
      "западня\t-0.101469\t11\r\n",
      "запятая\t-0.094803\t14\r\n",
      "застой\t0.044898\t13\r\n",
      "затея\t-0.168142\t12\r\n",
      "затишье\t0.078571\t16\r\n",
      "затмение\t0.270046\t12\r\n",
      "затруднение\t-0.015326\t15\r\n",
      "захоронение\t0.026095\t22\r\n",
      "звезда\t0.058544\t40\r\n",
      "звон\t0.009674\t14\r\n",
      "зеркало\t0.041695\t20\r\n",
      "зло\t0.044614\t23\r\n",
      "злоупотребление\t-0.078431\t12\r\n",
      "знак\t0.028556\t55\r\n",
      "знамя\t0.081691\t14\r\n",
      "значение\t0.082097\t30\r\n",
      "зонт\t-0.051948\t9\r\n",
      "\t0.035298\t2040\r\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate.py bert.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
